%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                 %
%                     SECTION                     %
%                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:sec001}

This document aims to describe the protocol and guidelines of the presented information. We perform a set of tests in the scope of both \hyperlink{https://github.com/MIMBCD-UI/prototype-multi-modality/releases/tag/v1.0.1-alpha}{v1.0.1-alpha} and \hyperlink{https://github.com/mida-project/prototype-multi-modality-assistant/releases/tag/v1.0.1-alpha}{v1.0.1-alpha} versions from both \hyperlink{https://github.com/MIMBCD-UI/prototype-multi-modality}{prototype-multi-modality} and \hyperlink{https://github.com/mida-project/prototype-multi-modality-assistant}{prototype-multi-modality-assistant} repositories. The repositories are part of the \hyperlink{https://mida-project.github.io/}{MIDA} project using traditional devices (mouse and keyboard). The goal of the test is to compare both prototypes, measuring the user performance, efficiency and efficacy metrics. The sessions will be recorded via video on a computer and using a record heat-map, while triggering event tools. It is guaranteed the confidentiality of the recordings, which will be used only for academic purpose. Also, we will use an \hyperlink{https://gaming.tobii.com/products/}{eye-tracking device} to track the clinician's eye movements during the breast cancer diagnosis.

Dividing the activity session into three distinct phases (\textbf{Pha\textit{N}.}, where \textit{N}. is the \textit{n}th number of a limited series, $n \in \mathbb{N}$ $\forall$ $N = \{1, ..., 10\}$) per each three activities representing two different scenarios: \textit{Multi-Modality} (\textbf{Sce1.}) vs \textit{Assistant} (\textbf{Sce2.}). The first two phases took place on an \hyperlink{https://github.com/MIMBCD-UI/testing-guide-breast/tree/master/samples/test_4}{early stage} of the \textit{User Tests}, while we were focus to publish the results on a near future. The third phase, will cover the hereby \textit{User Testing Guide}. Still, we will describe, as follows, the overall of the three phases to give higher contextualization.

Each scenario (\textbf{Sce\textit{M}.}, where \textit{M}. is the \textit{m}th number of a limited series, $m \in \mathbb{N}$ $\forall$ $M = \{1, 2\}$) will have three random patients (\textit{i.e.}, \textbf{Pat1.}, \textbf{Pat2.} or \textbf{Pat3.}) from a set of 50 total number of patients. For each patient (\textbf{Pat\textit{P}.}, where \textit{P}. is the \textit{p}th number of a limited series, $p \in \mathbb{N}$ $\forall$ $P = \{1, 2, 3\}$), we will choose it from the total set of patients randomly. We do it as follows, let \textit{R} be a random variable (\textbf{Rdm}) following the discrete uniform distribution as $r_{1}, r_{2}, r_{3} \in \mathbb{N}$ $\forall$ $R = \{1, ..., 50\}$. While $Pat1. = Rdm_{r_{1}}$ $\wedge$ $Pat2. = Rdm_{r_{2}}$ $\wedge$ $Pat3. = Rdm_{r_{3}}$ as soon as $r_{1}$ $\neq$ $r_{2}$ $\neq$ $r_{3}$ is \textit{True}. In both two scenarios, \textit{i.e.}, \textit{Multi-Modality} (\textbf{Sce1.}) and \textit{Assistant} (\textbf{Sce2.}), by supporting our traditional devices, the interaction is made with mouse and keyboard. Clinicians will classify each patient by using the \hyperlink{https://en.wikipedia.org/wiki/BI-RADS}{BIRADS}~\cite{balleyguier2007birads}. We will do several small questionnaires at the end of each scenario using \hyperlink{https://en.wikipedia.org/wiki/NASA-TLX}{NASA-TLX}~\cite{ramkumar2017using}, \hyperlink{https://en.wikipedia.org/wiki/System_usability_scale}{System Usability Scale (SUS)}~\cite{orfanou2015perceived} and measuring the \hyperlink{https://en.wikipedia.org/wiki/BI-RADS}{BIRADS}~\cite{balleyguier2007birads}.

Describing each phase, the first phase is nominated as \textbf{Pha1. User Characterization}. It is the \hyperlink{https://docs.google.com/spreadsheets/d/1h-4neEo3RbYsJs3JHBGvogHCvz3UFnMvsmoernfCuDU/edit?usp=sharing}{Demographic Questionnaire}, supporting our several characterizations of the clinician profile. For the major number of clinicians, this phase was committed on an \hyperlink{https://github.com/MIMBCD-UI/testing-guide-breast/tree/master/samples/test_4}{early stage}, as stated above. The \textbf{Pha1.} phase has three activities (\textbf{Act\textit{A}.}, where \textit{A}. is the \textit{a}th number of a limited series, $a \in \mathbb{N}$) which are described as follows. The first activity, named as \textbf{Act1. Consent Form}, serves the purpose of providing participants information about privacy of the data and accept to proceed the test. The second activity, named as \textbf{Act2. Study Introduction}, serves the purpose of giving participants project contextualization and task awareness. Last but not least, the third activity of \textbf{Pha1.} phase, called as \textbf{Act3. Demographic Questionnaires}, is where participants fill the survey regarding their characterization as a user.

\hfill

The second phase, nominated as \textbf{Pha2. Improving Visualization}, is also related with our later \href{https://github.com/MIMBCD-UI/prototype-breast-screening/wiki/User-Research#user-test-evaluations-}{User Test Evaluations}, corresponding to the tests done for the \textit{Multi-Modality} (\textbf{Sce1.}) scenario. At this \textbf{Pha2.} we divided it into two activities: (1) \textbf{Act4. First Scenario Introduction} activity; and (2) \textbf{Act5. First Scenario Evaluation} activity. The first \textbf{Act4.} activity, aims at providing participants information about what \textit{tasks} they will do. Each \textit{task} represents the diagnostic of each patient, while we named it as \textbf{Act5. First Scenario Evaluation} activity.

Finally, and most importantly, the third phase, nominated as \textbf{Pha3. Assistant Establishment} phase, is where clinicians proceed for the diagnosis of the respective three, \textit{i.e.}, \textbf{Pat1.}, \textbf{Pat2.} and \textbf{Pat3.}, patients. It is here, where we will also verify if our proposed designs impact \cite{amershi2019guidelines, kocielnik2019will} on user expectations, as intended, specifically as outlined by our several \textit{Hypotheses} (Section \ref{sec:sec007}) for the respective \textit{Research Questions} (Section \ref{sec:sec007}). We did it in regard to the novel introduction of an \textit{AI-Assisted} system. On this phase, we will measure the participants expectations concerning the \textit{AI-Assisted} system that we called \textbf{Act7. Second Scenario User Expectations} activity. The next \textbf{Act8. Second Scenario Introduction} activity, will be the introductory information about \textit{AI-Assisted} system and what feature are covered by the system. The \textbf{Act9. Second Scenario Evaluation} activity represents the diagnostic of each patient (same as the \textbf{Act5.} activity), but this time with support of our novel \textit{AI-Assisted} recommendations and explainability. And finally, the \textbf{Act10. Post-task Second Scenario Questions} activity will be a set of \textit{post-task} questions.

For the user tests we used a three distinct prototype repositories, \textit{i.e.}, the \hyperlink{https://github.com/MIMBCD-UI/prototype-multi-modality}{prototype-multi-modality} repository, the \hyperlink{https://github.com/mida-project/prototype-multi-modality-assistant}{prototype-multi-modality-assistant} repository and the \hyperlink{https://github.com/mida-project/prototype-heatmap}{prototype-heatmap} repository. The three are similar mirrors of the \hyperlink{https://github.com/MIMBCD-UI/prototype-breast-cancer}{prototype-breast-cancer} with major changes. The first repository, \textit{i.e.}, the \hyperlink{https://github.com/MIMBCD-UI/prototype-multi-modality}{prototype-multi-modality} repository, aims at providing clinicians a \textit{Multi-Modality} strategy view. The \textit{Multi-Modality} view, gives clinicians the possibility for the visualizing three modalities: (i) \hyperlink{https://medical-dictionary.thefreedictionary.com/mammography}{MammoGraphy (MG)}, both \hyperlink{https://medical-dictionary.thefreedictionary.com/craniocaudal}{CranioCaudal (CC)} and \hyperlink{https://www.thefreedictionary.com/mediolateral}{MedioLateral Oblique (MLO)} views; \hyperlink{https://www.thefreedictionary.com/UltraSound}{UltraSound (US)}; and \hyperlink{https://www.thefreedictionary.com/Magnetic+Resonance+Imaging}{Magnetic Resonance Imaging (MRI)}. This view corresponds to the \textbf{Sce1.} scenario of both \textbf{Act4.} and \textbf{Act5.} activities at the \textbf{Pha2.} phase. The second and third repositories, \textit{i.e.}, the \hyperlink{https://github.com/mida-project/prototype-multi-modality-assistant}{prototype-multi-modality-assistant} repository and the \hyperlink{https://github.com/mida-project/prototype-heatmap}{prototype-heatmap} repository, aims at providing clinicians a recommendation system regarding our \textit{AI-Assistive} techniques. Those techniques, will provide clinicians a twofold: (a) the opportunity of receive automatic recommendations concerning breast severities (\hyperlink{https://en.wikipedia.org/wiki/BI-RADS}{BIRADS}) of the patients; and (b) giving clinicians explainability (\hyperlink{https://www.darpa.mil/program/explainable-artificial-intelligence}{XAI})~\cite{gunning2017explainable, holzinger2017we} of those results. The automatic recommendations will be covered by the \hyperlink{https://github.com/mida-project/prototype-multi-modality-assistant}{prototype-multi-modality-assistant} repository, while the explainability will be covered by the \hyperlink{https://github.com/mida-project/prototype-heatmap}{prototype-heatmap} repository. Both techniques are corresponding to the \textbf{Sce2.} scenario of \textbf{Act7.}, \textbf{Act8.}, \textbf{Act9.} and \textbf{Act10.} activities at the \textbf{Pha3.} phase.